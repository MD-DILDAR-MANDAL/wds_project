{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.experimental import AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.image_size = (360, 360)\n",
    "        self.label_encoder = None\n",
    "    \n",
    "    def apply_augmentation(self, image, bbox):\n",
    "        bbox = tf.cast(bbox, tf.float32)\n",
    "        \n",
    "        h, w = float(self.image_size[0]), float(self.image_size[1])\n",
    "        bbox_pixel = bbox * tf.constant([w, h, w, h], dtype=tf.float32)\n",
    "        \n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            image = tf.image.flip_left_right(image)\n",
    "            bbox_pixel = tf.stack([\n",
    "                w - bbox_pixel[2],\n",
    "                bbox_pixel[1],    \n",
    "                w - bbox_pixel[0], \n",
    "                bbox_pixel[3]      \n",
    "            ])\n",
    "        \n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            angle = tf.random.uniform([], minval=-15, maxval=15) * math.pi / 180\n",
    "            image = tf.keras.layers.RandomRotation(\n",
    "                factor=(-15/360, 15/360),\n",
    "                fill_mode='constant',\n",
    "                fill_value=1.0\n",
    "            )(image)\n",
    "            \n",
    "            center_x = (bbox_pixel[0] + bbox_pixel[2]) / 2\n",
    "            center_y = (bbox_pixel[1] + bbox_pixel[3]) / 2\n",
    "            width = bbox_pixel[2] - bbox_pixel[0]\n",
    "            height = bbox_pixel[3] - bbox_pixel[1]\n",
    "            \n",
    "            cos_theta = tf.cos(angle)\n",
    "            sin_theta = tf.sin(angle)\n",
    "            new_center_x = (center_x - w/2) * cos_theta - (center_y - h/2) * sin_theta + w/2\n",
    "            new_center_y = (center_x - w/2) * sin_theta + (center_y - h/2) * cos_theta + h/2\n",
    "            \n",
    "            expansion_factor = 1.2\n",
    "            new_width = width * expansion_factor\n",
    "            new_height = height * expansion_factor\n",
    "            \n",
    "            bbox_pixel = tf.stack([\n",
    "                tf.clip_by_value(new_center_x - new_width/2, 0, w),\n",
    "                tf.clip_by_value(new_center_y - new_height/2, 0, h),\n",
    "                tf.clip_by_value(new_center_x + new_width/2, 0, w),\n",
    "                tf.clip_by_value(new_center_y + new_height/2, 0, h)\n",
    "            ])\n",
    "        \n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            zoom_factor = tf.random.uniform([], minval=0.9, maxval=1.0)\n",
    "            image = tf.image.central_crop(image, zoom_factor)\n",
    "            image = tf.image.resize(image, self.image_size)\n",
    "            \n",
    "            bbox_pixel = bbox_pixel * zoom_factor\n",
    "            bbox_pixel = tf.clip_by_value(bbox_pixel, 0, tf.maximum(w, h))\n",
    "        \n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            image = tf.image.random_brightness(image, 0.2)\n",
    "            image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "            image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "            image = tf.image.random_hue(image, 0.1)\n",
    "        \n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.01)\n",
    "            image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "        \n",
    "        bbox = bbox_pixel / tf.constant([w, h, w, h], dtype=tf.float32)\n",
    "        return image, bbox\n",
    "\n",
    "    def load_and_preprocess_image(self, filename, label, bbox):\n",
    "        try:\n",
    "            img = tf.io.read_file(filename)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, self.image_size)\n",
    "            img = tf.cast(img, tf.float32) / 255.0\n",
    "            \n",
    "            img, bbox = self.apply_augmentation(img, bbox)\n",
    "            \n",
    "            return img, label, bbox\n",
    "        except tf.errors.NotFoundError:\n",
    "            tf.print(f\"File not found: {filename}\")\n",
    "            return None, None, None\n",
    "            \n",
    "    def create_dataset(self, csv_file, base_dir, is_training=True, batch_size=16):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        if self.label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            df['class'] = self.label_encoder.fit_transform(df['class'])\n",
    "        else:\n",
    "            df['class'] = self.label_encoder.transform(df['class'])\n",
    "            \n",
    "        filenames = df['filename'].apply(lambda x: os.path.join(base_dir, x)).values\n",
    "        labels = df['class'].values\n",
    "        labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=len(self.label_encoder.classes_))\n",
    "        \n",
    "        bboxes = df[['xmin', 'ymin', 'xmax', 'ymax']].values.astype(np.float32)\n",
    "        \n",
    "        bboxes = bboxes / np.array([self.image_size[1], self.image_size[0], \n",
    "                                   self.image_size[1], self.image_size[0]], \n",
    "                                   dtype=np.float32)\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels_one_hot, bboxes))\n",
    "        dataset = dataset.map(\n",
    "            lambda f, l, b: (self.load_and_preprocess_image(f, l, b)),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        dataset = dataset.filter(lambda x, y, z: x is not None)\n",
    "        \n",
    "        def prepare_data(img, label, bbox):\n",
    "            return img, {'class_output': label, 'bbox_output': bbox}\n",
    "        \n",
    "        dataset = dataset.map(prepare_data)\n",
    "        \n",
    "        if is_training:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "        \n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionModel:\n",
    "    def __init__(self, num_classes, max_objects=10):\n",
    "        self.num_classes = num_classes\n",
    "        self.max_objects = max_objects  # Maximum number of objects to detect\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inputs = Input(shape=(360, 360, 3))\n",
    "        \n",
    "        # Base model\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(360, 360, 3))\n",
    "        for layer in base_model.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers:\n",
    "            if isinstance(layer, Conv2D):\n",
    "                layer.kernel_initializer = tf.keras.initializers.HeNormal()\n",
    "        \n",
    "        x = base_model(inputs, training=True)\n",
    "        \n",
    "        # Modified conv_block with additional features\n",
    "        def conv_block(x, filters):\n",
    "            x = Conv2D(filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.1)(x)\n",
    "            # Remove MaxPooling to preserve spatial information\n",
    "            return x\n",
    "        \n",
    "        # Feature Pyramid Network (FPN)-like structure\n",
    "        features = []\n",
    "        x1 = conv_block(x, 256)\n",
    "        features.append(x1)\n",
    "        \n",
    "        x2 = conv_block(x1, 256)\n",
    "        features.append(x2)\n",
    "        \n",
    "        x3 = conv_block(x2, 256)\n",
    "        features.append(x3)\n",
    "        \n",
    "        # Combine features from different scales\n",
    "        combined_features = Concatenate()([\n",
    "            GlobalAveragePooling2D()(f) for f in features\n",
    "        ])\n",
    "        \n",
    "        def fc_block(x, units, dropout_rate=0.5):\n",
    "            skip = x\n",
    "            x = Dense(units)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.1)(x)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            if skip.shape[-1] == units:\n",
    "                x = x + skip\n",
    "            return x\n",
    "        \n",
    "        x = fc_block(combined_features, 512)\n",
    "        x = fc_block(x, 256)\n",
    "        x = fc_block(x, 128)\n",
    "        \n",
    "        # Multiple object detection heads\n",
    "        class_outputs = []\n",
    "        bbox_outputs = []\n",
    "        confidence_outputs = []\n",
    "        \n",
    "        for _ in range(self.max_objects):\n",
    "            # Classification branch\n",
    "            class_branch = Dense(64)(x)\n",
    "            class_branch = LeakyReLU(alpha=0.1)(class_branch)\n",
    "            class_output = Dense(self.num_classes, activation='softmax')(class_branch)\n",
    "            class_outputs.append(class_output)\n",
    "            \n",
    "            # Bounding box branch\n",
    "            bbox_branch = Dense(64)(x)\n",
    "            bbox_branch = LeakyReLU(alpha=0.1)(bbox_branch)\n",
    "            bbox_output = Dense(4, activation='sigmoid')(bbox_branch)  # x, y, w, h\n",
    "            bbox_outputs.append(bbox_output)\n",
    "            \n",
    "            # Confidence branch\n",
    "            conf_branch = Dense(32)(x)\n",
    "            conf_branch = LeakyReLU(alpha=0.1)(conf_branch)\n",
    "            conf_output = Dense(1, activation='sigmoid')(conf_branch)  # Object confidence\n",
    "            confidence_outputs.append(conf_output)\n",
    "        \n",
    "        # Combine outputs\n",
    "        class_output = Concatenate(axis=-2)(class_outputs)\n",
    "        bbox_output = Concatenate(axis=-2)(bbox_outputs)\n",
    "        confidence_output = Concatenate(axis=-2)(confidence_outputs)\n",
    "        \n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs={\n",
    "                'class_output': class_output,  # Shape: (batch, max_objects, num_classes)\n",
    "                'bbox_output': bbox_output,    # Shape: (batch, max_objects, 4)\n",
    "                'conf_output': confidence_output  # Shape: (batch, max_objects, 1)\n",
    "            }\n",
    "        )\n",
    "        return model\n",
    "        \n",
    "    def compile_model(self, learning_rate=0.0001):\n",
    "        optimizer = AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=0.0001,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-07\n",
    "        )\n",
    "        \n",
    "        def confidence_loss(y_true, y_pred):\n",
    "            # Custom loss for confidence scores\n",
    "            return tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss={\n",
    "                'class_output': 'categorical_crossentropy',\n",
    "                'bbox_output': 'huber',\n",
    "                'conf_output': confidence_loss\n",
    "            },\n",
    "            loss_weights={\n",
    "                'class_output': 1.0,\n",
    "                'bbox_output': 1.0,\n",
    "                'conf_output': 0.5\n",
    "            },\n",
    "            metrics={\n",
    "                'class_output': ['accuracy'],\n",
    "                'bbox_output': ['mae'],\n",
    "                'conf_output': ['accuracy']\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def get_callbacks(self, model_dir='model/multi/'):\n",
    "        # Same as before\n",
    "        callbacks = [\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(model_dir, 'model-{epoch:02d}-{val_loss:.2f}.keras'),\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=1,\n",
    "                save_weights_only=False\n",
    "            )\n",
    "        ]\n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['class_output_accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_class_output_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model():\n",
    "    base_path = 'dataset/'\n",
    "    data_processor = DataProcessor(base_path)\n",
    "    \n",
    "    train_dataset = data_processor.create_dataset(\n",
    "        os.path.join(base_path, 'train', '_annotations.csv'),\n",
    "        os.path.join(base_path, 'train'),\n",
    "        is_training=True\n",
    "    )\n",
    "\n",
    "\n",
    "    valid_dataset = data_processor.create_dataset(\n",
    "        os.path.join(base_path, 'valid', '_annotations.csv'),\n",
    "        os.path.join(base_path, 'valid'),\n",
    "        is_training=False\n",
    "    )\n",
    "    \n",
    "    model = VisionModel(num_classes=len(data_processor.label_encoder.classes_))\n",
    "    model.compile_model()\n",
    "    \n",
    "    history = model.model.fit(\n",
    "        train_dataset,\n",
    "        epochs=100,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=model.get_callbacks(),\n",
    "        workers=4,\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    model_save_path = 'model/multi/my_model.h5'\n",
    "    model.model.save(model_save_path)\n",
    "    print(f'Model saved to: {model_save_path}')\n",
    "    plot_metrics(history)\n",
    "    return model, history, data_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_7/kernel:0', 'dense_7/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_43/kernel:0', 'dense_43/bias:0', 'dense_49/kernel:0', 'dense_49/bias:0', 'dense_55/kernel:0', 'dense_55/bias:0', 'dense_61/kernel:0', 'dense_61/bias:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_20/kernel:0', 'dense_20/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_50/kernel:0', 'dense_50/bias:0', 'dense_56/kernel:0', 'dense_56/bias:0', 'dense_62/kernel:0', 'dense_62/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_7/kernel:0', 'dense_7/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_43/kernel:0', 'dense_43/bias:0', 'dense_49/kernel:0', 'dense_49/bias:0', 'dense_55/kernel:0', 'dense_55/bias:0', 'dense_61/kernel:0', 'dense_61/bias:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_20/kernel:0', 'dense_20/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_50/kernel:0', 'dense_50/bias:0', 'dense_56/kernel:0', 'dense_56/bias:0', 'dense_62/kernel:0', 'dense_62/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 652, in _get_metric_object\n        y_t_rank = len(y_t.shape.as_list())\n\n    AttributeError: 'NoneType' object has no attribute 'shape'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, history, data_processor \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m VisionModel(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_processor\u001b[38;5;241m.\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile_model()\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/multi/my_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(model_save_path)\n",
      "File \u001b[1;32md:\\testing\\.testenv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0b_lvwz4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"d:\\testing\\.testenv\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 652, in _get_metric_object\n        y_t_rank = len(y_t.shape.as_list())\n\n    AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "model, history, data_processor = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = data_processor.create_dataset(\n",
    "        os.path.join('dataset', 'test', '_annotations.csv'),\n",
    "        os.path.join('dataset', 'test'),\n",
    "        is_training=False\n",
    "    )\n",
    "\n",
    "    # Predictions on test data\n",
    "class_pred, bbox_pred = model.model.predict(test_dataset)\n",
    "class_pred_labels = np.argmax(class_pred, axis=1)\n",
    "\n",
    "    # Extract true class labels from test dataset\n",
    "true_class_labels = []\n",
    "for images, labels in test_dataset.unbatch():\n",
    "    true_class_labels.append(np.argmax(labels['class_output']))\n",
    "\n",
    "true_class_labels = np.array(true_class_labels)\n",
    "\n",
    "    # Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_class_labels, class_pred_labels, target_names=data_processor.label_encoder.classes_))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_class_labels, class_pred_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=data_processor.label_encoder.classes_, yticklabels=data_processor.label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/multi/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(test_dataset)\n",
    "\n",
    "# Unpack the results\n",
    "test_loss, class_output_loss, bbox_output_loss, test_accuracy, top_k_categorical_accuracy, bbox_output_mae, bbox_output_mean_squared_error = results\n",
    "\n",
    "# Print the relevant metrics\n",
    "print(f'Test Accuracy: {test_accuracy}, Test Loss: {test_loss}')\n",
    "print(f'Bounding Box MAE: {bbox_output_mae}, Bounding Box MSE: {bbox_output_mean_squared_error}')\n",
    "print(f'Top-k Categorical Accuracy: {top_k_categorical_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'dataset/'\n",
    "data_processor = DataProcessor(base_path)\n",
    "test_dataset = data_processor.create_dataset(\n",
    "    os.path.join(base_path, 'test', '_annotations.csv'),\n",
    "    os.path.join(base_path, 'test'),\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset CSV file and encode true labels\n",
    "test_csv_path = os.path.join(base_path, 'test', '_annotations.csv')\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Encode class labels using the same LabelEncoder\n",
    "if data_processor.label_encoder is None:\n",
    "    data_processor.label_encoder = LabelEncoder()\n",
    "    data_processor.label_encoder.fit(df_test['class'])\n",
    "\n",
    "# Convert class labels to integers for true labels\n",
    "true_labels = data_processor.label_encoder.transform(df_test['class'])\n",
    "\n",
    "class_predictions, bbox_predictions = y_pred  # Extract class and bbox predictions\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "predicted_classes = class_predictions.argmax(axis=1)\n",
    "\n",
    "# Classification report for precision, recall, and F1-score\n",
    "print(classification_report(true_labels, predicted_classes, target_names=data_processor.label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(image, pred_boxes, true_boxes=None):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    if pred_boxes is not None:\n",
    "        for box in pred_boxes:\n",
    "            if isinstance(box, np.ndarray):\n",
    "                x = box[0] * width\n",
    "                y = box[1] * height\n",
    "                w = box[2] * width\n",
    "                h = box[3] * height\n",
    "                \n",
    "                plt.gca().add_patch(plt.Rectangle((x, y), w, h, \n",
    "                                                fill=False, \n",
    "                                                color='red', \n",
    "                                                linewidth=2,\n",
    "                                                label='Predicted'))\n",
    "    \n",
    "    # Draw ground truth boxes (handle multiple)\n",
    "    if true_boxes is not None:\n",
    "        for box in true_boxes:\n",
    "            if isinstance(box, np.ndarray):\n",
    "                x = box[0] * width\n",
    "                y = box[1] * height\n",
    "                w = box[2] * width\n",
    "                h = box[3] * height\n",
    "                \n",
    "                plt.gca().add_patch(plt.Rectangle((x, y), w, h, \n",
    "                                                fill=False, \n",
    "                                                color='green', \n",
    "                                                linewidth=2,\n",
    "                                                label='Ground Truth'))    \n",
    "                \n",
    "    plt.legend()\n",
    "    plt.axis('on')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of data from the test dataset\n",
    "test_dataset_iter = iter(test_dataset)  # Create an iterator\n",
    "batch = next(test_dataset_iter)  # Extract one batch\n",
    "\n",
    "# Extract image and true bounding boxes from the batch\n",
    "image = batch[0][0].numpy()  # Get the first image in the batch and convert to numpy\n",
    "true_boxes = batch[1]['bbox_output'][0].numpy()  # Get the true bounding boxes for the first image\n",
    "\n",
    "# Predict bounding boxes\n",
    "pred_boxes = model.predict(image[np.newaxis, ...])[1][0]  # Predict bounding boxes and take the first prediction\n",
    "# Before plotting, let's verify the box coordinates\n",
    "print(\"Predicted boxes shape:\", pred_boxes.shape)\n",
    "print(\"True boxes shape:\", true_boxes.shape)\n",
    "print(\"Image shape:\", image.shape)\n",
    "\n",
    "# Plot the image with predicted and true bounding boxes\n",
    "plot_image_with_boxes(image, [pred_boxes], [true_boxes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5  # Set the number of images you want to visualize\n",
    "for i, batch in enumerate(test_dataset.take(num_images)):\n",
    "    # Extract image and true bounding boxes\n",
    "    image = batch[0][0].numpy()\n",
    "    true_boxes = batch[1]['bbox_output'][0].numpy()\n",
    "    \n",
    "    # Predict bounding boxes\n",
    "    pred_boxes = model.predict(image[np.newaxis, ...])[1][0]\n",
    "    \n",
    "    # Plot the image with predicted and true bounding boxes\n",
    "    plot_image_with_boxes(image, [pred_boxes], [true_boxes])\n",
    "    \n",
    "    if i >= num_images - 1:\n",
    "        break  # Stop after displaying the desired number of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(image, pred_boxes, true_boxes=None, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Draw predicted boxes\n",
    "    if pred_boxes is not None:\n",
    "        for box in pred_boxes:\n",
    "            x = box[0] * width\n",
    "            y = box[1] * height\n",
    "            w = box[2] * width\n",
    "            h = box[3] * height\n",
    "\n",
    "            ax.add_patch(plt.Rectangle((x, y), w, h, \n",
    "                                         fill=False, \n",
    "                                         color='red', \n",
    "                                         linewidth=2,\n",
    "                                         label='Predicted'))\n",
    "\n",
    "    # Draw ground truth boxes\n",
    "    if true_boxes is not None:\n",
    "        for box in true_boxes:\n",
    "            x = box[0] * width\n",
    "            y = box[1] * height\n",
    "            w = box[2] * width\n",
    "            h = box[3] * height\n",
    "\n",
    "            ax.add_patch(plt.Rectangle((x, y), w, h, \n",
    "                                         fill=False, \n",
    "                                         color='green', \n",
    "                                         linewidth=2,\n",
    "                                         label='Ground Truth'))\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "def plot_multiple_images(test_dataset, num_images, rows, cols):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 4*rows))\n",
    "    axes = axes.ravel()  # Flatten the axes array\n",
    "    \n",
    "    for i, batch in enumerate(test_dataset.take(num_images)):\n",
    "        if i >= num_images:\n",
    "            break\n",
    "            \n",
    "        # Extract image and true bounding boxes\n",
    "        image = batch[0][0].numpy()\n",
    "        true_boxes = batch[1]['bbox_output'][0].numpy()\n",
    "        \n",
    "        # Predict bounding boxes\n",
    "        pred_boxes = model.predict(image[np.newaxis, ...])[1][0]\n",
    "        \n",
    "        # Plot using the modified function\n",
    "        plot_image_with_boxes(image, [pred_boxes], [true_boxes], ax=axes[i])\n",
    "        axes[i].set_title(f'Image {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Specify the layout\n",
    "num_images = 30  # Total number of images\n",
    "rows = 5       # Number of rows\n",
    "cols = 6        # Number of columns\n",
    "\n",
    "# Plot the grid of images\n",
    "plot_multiple_images(test_dataset, num_images, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
